<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Getting Started with `mpcmp` (under construction) • mpcmp</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.3.7/lumen/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Getting Started with `mpcmp` (under construction)">
<meta property="og:description" content="">
<meta property="og:image" content="/logo.png">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">mpcmp</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.3.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../news/index.html">Change log</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/thomas-fung/mpcmp">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/people.html">
    <span class="fa fa-info-circle fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Getting Started with <code>mpcmp</code> (under construction)</h1>
                        <h4 class="author">Thomas Fung, Aya Alwan, Justin Wishart and Alan Huang</h4>
            
            <h4 class="date">2020-03-20</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/thomas-fung/mpcmp/blob/master/vignettes/mpcmp.Rmd"><code>vignettes/mpcmp.Rmd</code></a></small>
      <div class="hidden name"><code>mpcmp.Rmd</code></div>

    </div>

    
    
<div id="intro" class="section level2">
<h2 class="hasAnchor">
<a href="#intro" class="anchor"></a>Introduction</h2>
<p>Conway–Maxwell–Poisson (CMP or COM-Poisson) distributions have seen a recent resurgence in popularity for the analysis of dispersed counts (e.g., <span class="citation">Shmueli et al. (2005)</span>; <span class="citation">(<span class="citeproc-not-found" data-reference-id="Lord2008"><strong>???</strong></span>)</span>, <span class="citation">(<span class="citeproc-not-found" data-reference-id="Lord2010"><strong>???</strong></span>)</span>; <span class="citation">Sellers and Shmueli (2010)</span>). Key features of COM-Poisson distributions include the ability to handle both overdispersion and underdispersion, containing the classical Poisson distribution as a special case, and being a continuous bridge between other classical distributions such as the geometric and Bernoulli distributions. COM-Poisson distributions are also full probability models, making them particularly useful for predictions and estimation of event probabilities. See <span class="citation">Shmueli et al. (2005)</span> for a more detailed overview of the history, features and applications of CMP distributions.</p>
<p>The R (<span class="citation">(<span class="citeproc-not-found" data-reference-id="R-base"><strong>???</strong></span>)</span>) <code>mpcmp</code> package (<span class="citation">(<span class="citeproc-not-found" data-reference-id="R-mpcmp"><strong>???</strong></span>)</span>) provides functionality for estimating a mean-parametrized Conway-Maxwell-Poisson generalzied linear models for dispersed count data. In this way, the</p>
<p>The package is available from the Comprehensive R Archive Network (CRAN) at . <span class="citation">Huang (2017)</span> provides the theoretical development of the model that this package bases on.</p>
</div>
<div id="cmpintro" class="section level2">
<h2 class="hasAnchor">
<a href="#cmpintro" class="anchor"></a>Conway-Maxwell-Poisson Distributions</h2>
<p>The CMP distribution was first used by <span class="citation">(<span class="citeproc-not-found" data-reference-id="Conway1962"><strong>???</strong></span>)</span> as a model for queuing system with dependent service times. A random variable is said to have a (standard) CMP distribution with rate parameter <span class="math inline">\(\lambda\)</span> and dispersion parameter <span class="math inline">\(\nu\)</span> if its probability mass function (pmf) is given by <span class="math display">\[
P(Y =y|λ,ν)= \frac{\lambda^y}{(y!)^{\nu}}\frac{1}{Z(\lambda,\nu)}, \quad y =0,1,2,...,
\]</span> where <span class="math display">\[
Z(\lambda,\nu)= \sum^{\infty}_{y=0}\frac{\lambda^y}{(y!)^{\nu}},
\]</span> is a normalizing constant. The CMP includes Poisson (<span class="math inline">\(\nu = 1\)</span>), geometric (<span class="math inline">\(\nu = 0\)</span>, <span class="math inline">\(\lambda &lt; 1\)</span>) and Bernoulli (<span class="math inline">\(\nu \to \infty\)</span> with probability <span class="math inline">\(\lambda/(1+\lambda)\)</span>).</p>
<p>One of the major limitations of CMP distributions is that it is not directly parametrized via the mean as it does not have closed-form expression for its moments in terms of the parameters <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\nu\)</span> but satisfy recursive formulas, <span class="math display">\[
\begin{aligned}
E(Y)  &amp;= \lambda E(Y+1)^{1-\nu};  \\
E(Y^{r+1}) &amp;=  \lambda\frac{d}{d\lambda}E(Y^r) + E(Y)E(Y^r),  \quad r&gt;0.
\end{aligned}
\]</span> For the first two moments, approximation can be obtained as <span class="math display">\[
\begin{aligned}
E(Y)  &amp;= \frac{\partial \log Z}{\partial \log\lambda} \approx \lambda^{\frac{1}{\nu}}-\frac{\nu-1}{2\nu};\\
Var(Y)  &amp;= \frac{\partial^2\log Z}{\partial (\log \lambda)^2} \approx \frac{1}{\nu} \lambda^{\frac{1}{\nu}} \approx \frac{1}{\nu}E(Y),
\end{aligned}
\]</span> and they can be particularly accurate for <span class="math inline">\(\nu\leq 1\)</span> or <span class="math inline">\(\lambda&gt;10^{\nu}\)</span> (see <span class="citation">Shmueli et al. (2005)</span>). It is obvious that <span class="math inline">\(E(Y) \ne \lambda\)</span> unless <span class="math inline">\(\nu=1\)</span> i.e. the Poisson special case.</p>
<p>The two model parameters, namely, the rate <span class="math inline">\(\lambda \geq 0\)</span> and the dispersion <span class="math inline">\(\nu \geq 0\)</span>, are often interpreted through ratios of successive probabilities via <span class="math display">\[
\frac{P(Y = y − 1)}{P(Y= y)} = \frac{y^{\nu}}{\lambda}.
\]</span> As a result, the CMP generalises the Poisson such that the ratio is not necessarily linear in <span class="math inline">\(y\)</span>. If <span class="math inline">\(\nu &lt; 1\)</span>, CMP would have a longer tail relative to a Poisson distribution with the same mean and is therefore overdispersed. In reverse, CMP is underdispersed when <span class="math inline">\(\nu&gt;1\)</span>.</p>
<p>As CMP is one of a few distributions that can handle both under- and over-dispersion, the aim is to extend the GLM formulation to the CMP case so that one can model the relationship between <span class="math inline">\(Y\)</span> and the predictors <span class="math inline">\(X\)</span>. Given a set of covariates <span class="math inline">\(X \in R^q\)</span>, <span class="citation">Sellers and Shmueli (2010)</span> proposed a GLM for count response <span class="math inline">\(Y\)</span> that can be specified via <span class="math display">\[
Y|X ∼ CMP(\lambda,\nu), \quad \text{s.t.} \quad \log\lambda = X^{\top}\beta
\]</span> where <span class="math inline">\(\beta \in R^q\)</span> is a vector of regression coefficients. This model however does not provide a closed form relationship between <span class="math inline">\(E(Y)\)</span> and the linear predictor, making it incompatible with other commonly used log-linear model.</p>
</div>
<div id="mpcmpintro" class="section level2">
<h2 class="hasAnchor">
<a href="#mpcmpintro" class="anchor"></a>Mean-Parametrized Conway-Maxwell-Poisson Regression</h2>
<p>As it is more convenient and interpretable to model the mean <span class="math inline">\(\mu = E(Y)&gt;0\)</span> of the distribution directly, <span class="citation">Huang (2017)</span> proposed to parametrize the CMP distribution via the mean: <span class="math display">\[
P(Y = y|\mu, \nu) = \frac{\lambda(\mu,\nu)^{y}}{(y!)^{\nu}}\frac{1}{Z(\lambda(\mu,\nu),\nu)}, \quad y = 0,1,2,\ldots,
\]</span> where the rate <span class="math inline">\(\lambda(\mu,\nu)\)</span> is defined as the solution to the mean constraint: <span class="math display">\[
 \mu= \sum^{\infty}_{y=0} y\frac{\lambda^y}{(y!)^{\nu}}\frac{1}{Z(\lambda,\nu)}.
\]</span> We shall denote this as CMP<span class="math inline">\(_{\mu}(\mu, \nu)\)</span> distribution to distinguish it from the original/standard one.</p>
<p>A GLM that based on CMP<span class="math inline">\(_{\mu}\)</span> can then be specified via <span class="math display">\[
Y|X ∼ CMP_{\mu}(\mu(X^{\top}\beta),\nu), 
\]</span> where <span class="math display">\[
E(Y|X) = \mu(X^{\top}\beta) = \exp(X^{\top}\beta).
\]</span> Note that GLM that based on CMP<span class="math inline">\(_{\mu}\)</span> is a genuine GLM, so the score equations for the regression parameters have the usual ‘weighted least-squares’ form (cf. Fahrmeir and Kaufman, 1985) and can be solved using standard Newton–Raphson or Fisher scoring algorithms (see Section estimation). Moreover, all the familiar key features of GLMs (e.g., McCullagh &amp; Nelder, 1989, Chapter 2) are retained.</p>
<p>The mean-dispersion specification makes CMP<span class="math inline">\(_{\mu}\)</span> directly comparable and compatible other commonly used log-linear regression models for counts. In particular, the mean <span class="math inline">\(\mu = \exp(X^{\top}\beta)\)</span> is functionally independent of the dispersion parameter <span class="math inline">\(\nu\)</span>, making it similar in structure to the familiar Negative Binomial regression model for overdispersed counts.</p>
<p>Another advantage of modelling the mean directly is that it is way easier to incorporate offsets into the model, much in the same way as for classical GLMs (e.g., McCullagh &amp; Nelder, 1989, Page 206). In contrast, handling offsets in standard CMP regression models is not as easy, precisely because standard CMP distributions are not parametrized via the mean.</p>
</div>
<div id="model-fitting" class="section level2">
<h2 class="hasAnchor">
<a href="#model-fitting" class="anchor"></a>Model fitting</h2>
<p>Given <span class="math inline">\(n\)</span> successive observations <span class="math inline">\(\{y_t: t = 1, \ldots ,n\}\)</span> on the response series the likelihood is constructed as the product of conditional densities of Yt given Ft. The state vector Wt at each time embodies these conditioning variables and so the log likelihood is given by n l(δ) = 􏰊 log fYt|Wt (yt|Wt; δ). (7) t=1 For the Poisson and binomial response distributions the log-likelihood (7) is where δ = (β, φ, θ). n l(δ) = 􏰊{ytWt(δ) − atb(Wt(δ)) + ct} (8) t=1 For the negative binomial response distribution the log-likelihood is more complicated because the shape parameter α also has to be estimated along with β, φ and θ. We then let δ = (β, φ, θ, α). Note that et in (4), the Zt in (5) and thus the Wt in (2) are functions of the unknown parameter δ and hence need to be recomputed for each iteration of the likelihood optimization. Thus in order to calculate the likelihood and its derivatives, recursive expressions are needed to calculate et, Zt and Wt as well as their first and second partial derivative with respect to δ. Expressions for these recursive formulae are available in Davis et al. (2005) for the Poisson case. Corresponding formulae for the binomial case were derived in Lu (2002) and for the negative binomial case in Wang (2004). The essential computational cost is in the recursions for Zt and Wt and their first and second derivative with respect to δ. Fortunately, these require identical code for the various response distributions and definitions of predictive residuals et. For calculation of the Zt in (5), initializing conditions for the recursions must be used. The current implementation in glarma is to set et = 0 and Zt = 0 for t ≤ 0 ensuring that the conditional and unconditional expected values of et are zero for all t. The likelihood is maximized from a suitable starting value of the parameter δ using a version of Fisher scoring iteration or by Newton-Raphson iteration. For a given value of δ let the vector of first derivatives with respect to δ of the log-likelihood (7) be and the second derivative matrix be d(δ) = ∂l(δ) ∂δ DNR(δ) = ∂2l(δ) , (9) ∂δ∂δ⊤ where the matrix of second derivatives of the log-likelihood is (in the Poisson and binomial response cases) given by 􏰊n ∂ 2 W t 􏰊n ∂ W t ∂ W t DNR(δ) = [yt − atb ̇(Wt)]∂δ∂δ⊤ − at ̈b(Wt) ∂δ ∂δ⊤ . (10) t=1 t=1</p>
<p>and b ̇(u) and ̈b(u) are the first and second derivatives respectively of the function b(u) with respect to the argument u. Using the fact that, at the true parameter value δ, E[yt − atb ̇(Wt)|Ft] = 0 the expected value the first summation in (10) is zero and hence the expected value of the matrix of second derivatives is E[DFS(δ)] where DFS(δ) = − Note also that due to the martingale difference property of the predictive residuals we also have E[DNR(δ)] = −E[d(δ)d(δ)⊤]. While these expectations cannot be computed in closed form, expression (11) requires first derivatives only and is used in package glarma as the basis for the approximate Fisher scoring method. Thus, if δ(k) is the parameter vector at the current iterate k, the Newton-Raphson updates proceed using δ(k+1) = δ(k) − DNR(δ(k))−1d(δ(k)) (12) and the approximate Fisher scoring updates use DFS in place of DNR Given a specified tolerance TOL, iterations continue until the largest gradient of the log- likelihood satisfies maxi |di(δ(k)|) ≤ TOL or a maximum number of iterations MAXITER is surpassed.</p>
<p>Start with some initial guesses of <span class="math inline">\(\hat{\beta}^{(0)}\)</span> (those from Poisson GLM work well), and use FS to generate a sensible initial value <span class="math inline">\(\hat{\nu}^{(0)}\)</span> starting from the Poisson special case i.e. <span class="math inline">\(\nu^{(0,0)} = 1\)</span>. Fixing <span class="math inline">\(\beta\)</span> at <span class="math inline">\(\hat{\beta}^{(0)}\)</span>, the <span class="math inline">\(\nu\)</span> update is: <span class="math display">\[
\hat{\nu}^{(0,m)} =\hat{\nu}^{(0,m-1)} +  [\mathcal{I}^{(0,m)}]^{-1}U^{(0,m)},
\]</span> where <span class="math inline">\(U^{(0,m)}\)</span> &amp; <span class="math inline">\(\mathcal{I}^{(0,m)}\)</span> is the score and information matrix evaluated at <span class="math inline">\(\hat{\lambda}^{(0,m-1)}\)</span> &amp; <span class="math inline">\(\hat{\nu}^{(0,m-1)}\)</span> respectively. Given a specified tolerance TOL, iterations on <span class="math inline">\(\nu\)</span> would continue until the relative change of the log-likelihood is small relative to the tolerance, i.e. |di(δ(k)|) ≤ TOL, the update to <span class="math inline">\(\nu\)</span> is small relative to the tolerance, i.e. <span class="math inline">\(|\hat{\nu}^{(0,m)}-\hat{\nu}^{0,m-1}|\leq TOL\)</span> or a maximum number of iterations is surpassed. Then we set <span class="math inline">\(\hat{\nu}^{(0)} = \hat{\nu}^{(0,m)}\)</span>.</p>
<p><span class="math inline">\(\beta\)</span> and <span class="math inline">\(\nu\)</span> would then be updated tegether until convergence. Given CMP<span class="math inline">\(_{\mu}\)</span> belongs to the exponential family, we can update <span class="math inline">\(\beta\)</span> using standard iteratively reweighted least squares: <span class="math display">\[
\hat{\beta}^{(m)} = \left(X^{\top}WX\right)^{-1}X^{\top}Wz,
\]</span> where <span class="math inline">\(z\)</span> are the local dependant variable, using <span class="math inline">\(\hat{\lambda}^{(m-1)}\)</span> and <span class="math inline">\(\hat{\nu}^{(m-1)}\)</span>. If the (log)-likelihood is not increasing or <span class="math inline">\(\hat{\nu}^{(m)}\)</span> is out-of-bound}, we will carry out a half-step correction (<span class="citation">Marschner (2011)</span>) i.e. <span class="math display">\[
\begin{aligned}
\hat{\beta}^{(m)} &amp; \leftarrow \frac{1}{2}\left[ \hat{\beta}^{(m)} + \hat{\beta}^{(m-1)}\right];\\
\hat{\nu}^{(m)} &amp;\leftarrow \frac{1}{2}\left[ \hat{\nu}^{(m)} + \hat{\nu}^{(m-1)}\right].
\end{aligned}
\]</span></p>
<p>As the (log-)likelihood is in terms of <span class="math inline">\(\lambda(\mu,\nu)\)</span>, we need solve for a set of <span class="math inline">\(\lambda\)</span>s by solving for <span class="math inline">\(\hat{\lambda}^{(m)}\)</span> from the mean constraints: <span class="math display">\[
e^{\boldsymbol{X}^{\top}\beta} = \mu = \sum^{\infty}_{y=0} y\frac{\lambda^y}{(y!)^{\nu} Z(\lambda,\nu)},
\]</span> whenever we generated a new update to <span class="math inline">\(\widehat{\nu}\)</span> or <span class="math inline">\(\widehat{\beta}\)</span>, by using a combination of bisection and Newton Raphson updates.</p>
<p>At termination, we let <span class="math inline">\((\widehat{\beta},\widehat{\nu}) = (\widehat{\beta}^{(m)},\widehat{\nu}^{(m)})\)</span> and call this the ``maximum likelihood estimate’’ of <span class="math inline">\((\beta,\nu)\)</span>.</p>
</div>
<div id="dist_theory" class="section level2">
<h2 class="hasAnchor">
<a href="#dist_theory" class="anchor"></a>Distribution theory for likelihood estimation</h2>
<p>For inference, <span class="citation">Huang (2017)</span> showed that the central limit theory for the likelihood estimates hold so that <span class="math display">\[\binom{\widehat{\beta}}{\widehat{\nu}} \overset{d}{\approx} N\left(\binom{\beta}{\nu}, \widehat{\Omega}\right),\]</span> where the approximate covariance matrix is estimated by <span class="math display">\[\widehat{\Omega} = -\left(D_{FS}(\widehat{\beta},\widehat{\nu})\right)^{-1}.\]</span> Thus a standard error for the maximum likelihood estimates of the <em>i</em>th component of <span class="math inline">\(\beta\)</span> is computed using <span class="math inline">\(\widehat{\Omega}_{ii}^{\frac{1}{2}}\)</span>.</p>
</div>
<div id="modelling-function-in-mpcmp" class="section level2">
<h2 class="hasAnchor">
<a href="#modelling-function-in-mpcmp" class="anchor"></a>Modelling function in mpcmp</h2>
<p>The main modelling function for fitting mean-parametrized CMP models is <code>glm.cmp</code>. The object returned by any of the fitting routines is of class <code>cmp</code>. To specify the model in a call to <code>glm.cmp</code>, a symbolic desciption of the model to be fitted needs to be provided as an object of class <code>formula</code>. An optional offset term must be specified also. Initial values can be given for the coefficients in the regression component using the argument <code>beta</code>. A call is made to the Poisson GLM to obtain initial regression coefficient values for <span class="math inline">\(\beta\)</span> and set <span class="math inline">\(\nu=1\)</span>.</p>
<p>Because we need to find <span class="math inline">\(\lambda\)</span>s that can satisfy the mean constraints numerically, we have <code>lambdalb</code>, <code>lambdaub</code>, <code>maxlambdaiter</code> and <code>tol</code> to control where the search should be conducted and when the search would be stopped.</p>
<p>Once a fitted model object has been obtained, there are accessor functions available using <code>S3</code> methods to extract the coefficients (<code><a href="https://rdrr.io/r/stats/coef.html">coef()</a></code>, or its alias <code><a href="https://rdrr.io/r/stats/coef.html">coefficients()</a></code>), the fitted values (<code><a href="https://rdrr.io/r/stats/fitted.values.html">fitted()</a></code> or its alias <code><a href="https://rdrr.io/r/stats/fitted.values.html">fitted.values()</a></code>), the residuals (<code><a href="https://rdrr.io/r/stats/residuals.html">residuals()</a></code> or its alias <code><a href="https://rdrr.io/r/stats/residuals.html">resid()</a></code>), the model frame (<code><a href="https://rdrr.io/r/stats/model.frame.html">model.frame()</a></code>), the number of observations (nobs()), the log-likelihood (<code><a href="https://rdrr.io/r/stats/logLik.html">logLik()</a></code>), and the AIC (<code><a href="https://rdrr.io/r/stats/AIC.html">AIC()</a></code>). These are standard implementations of the methods.</p>
<p>For an object of the fitted model class <code>cmp</code> the package also includes S3 print, summary, and plot methods.</p>
<p>Vignettes are long form documentation commonly included in packages. Because they are part of the distribution of the package, they need to be as compact as possible. The <code>html_vignette</code> output type provides a custom style sheet (and tweaks some options) to ensure that the resulting html is as small as possible. The <code>html_vignette</code> format:</p>
<ul>
<li>Never uses retina figures</li>
<li>Has a smaller default figure size</li>
<li>Uses a custom CSS stylesheet instead of the default Twitter Bootstrap style</li>
</ul>
</div>
<div id="diagnostics" class="section level2">
<h2 class="hasAnchor">
<a href="#diagnostics" class="anchor"></a>Diagnostics</h2>
<div id="likelihood-ratio-test" class="section level3">
<h3 class="hasAnchor">
<a href="#likelihood-ratio-test" class="anchor"></a>Likelihood ratio test</h3>
</div>
<div id="probability-integral-transformation" class="section level3">
<h3 class="hasAnchor">
<a href="#probability-integral-transformation" class="anchor"></a>Probability integral transformation</h3>
</div>
<div id="plots" class="section level3">
<h3 class="hasAnchor">
<a href="#plots" class="anchor"></a>Plots</h3>
<p>The plot method for objects of class <code>cmp</code> produces four plots by default: a plot of deviance residuals against fitted values; a histogram of the (non-randomized) uniform PIT values; a scale-location plot; and a plot of standardized pearson residuals against against leverage values. Additional four plots can be produced: a Q-Q plot of the (non-randomized) uniform PIT values; a histogram of the normal randomzied residuals; a Q-Q plot of the normal randomized residuals; a plot of the cook’s distance against observation number. Any subset of these eight plots can be obtained using the <code>which</code> arguments. For example the default value of <code>which</code> is set to <code>which = c(1L, 2L, 6L, 8L)</code>. There is an optional <code>bin</code> argument to change the number of bins being used for the PIT in these plots.</p>
</div>
</div>
<div id="examples" class="section level2">
<h2 class="hasAnchor">
<a href="#examples" class="anchor"></a>Examples</h2>
<p>There are three example datasets currently included in the <code>mpcmp</code> package which cover over- and under-dispersed counts. Sample analyses for these datsets are provided in either the help page for the datasets or for the <code><a href="../reference/glm.cmp.html">glm.cmp()</a></code> function.</p>
<div id="overdispersed-attendance-data" class="section level3">
<h3 class="hasAnchor">
<a href="#overdispersed-attendance-data" class="anchor"></a>Overdispersed attendance data</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="st">"mpcmp"</span>)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw"><a href="https://rdrr.io/r/utils/data.html">data</a></span>(<span class="st">"attendance"</span>)</a>
<a class="sourceLine" id="cb1-3" data-line-number="3">M.attendance &lt;-<span class="st"> </span><span class="kw"><a href="../reference/glm.cmp.html">glm.cmp</a></span>(daysabs<span class="op">~</span><span class="st"> </span>gender<span class="op">+</span>math<span class="op">+</span>prog, <span class="dt">data=</span>attendance)</a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="kw"><a href="https://rdrr.io/r/base/print.html">print</a></span>(M.attendance)</a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="co">#&gt; Call: glm.cmp(formula = daysabs ~ gender + math + prog, data = attendance)</span></a>
<a class="sourceLine" id="cb1-7" data-line-number="7"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb1-8" data-line-number="8"><span class="co">#&gt; Linear Model Coefficients:</span></a>
<a class="sourceLine" id="cb1-9" data-line-number="9"><span class="co">#&gt;    (Intercept)      gendermale            math    progAcademic  progVocational  </span></a>
<a class="sourceLine" id="cb1-10" data-line-number="10"><span class="co">#&gt;        2.75000        -0.23600        -0.00681        -0.42600        -1.27000  </span></a>
<a class="sourceLine" id="cb1-11" data-line-number="11"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb1-12" data-line-number="12"><span class="co">#&gt; Dispersion (nu): 0.0242</span></a>
<a class="sourceLine" id="cb1-13" data-line-number="13"><span class="co">#&gt; Degrees of Freedom: 313 Total (i.e. Null);  309 Residual</span></a>
<a class="sourceLine" id="cb1-14" data-line-number="14"><span class="co">#&gt; Null Deviance: 462.9562 </span></a>
<a class="sourceLine" id="cb1-15" data-line-number="15"><span class="co">#&gt; Residual Deviance: 383.0771 </span></a>
<a class="sourceLine" id="cb1-16" data-line-number="16"><span class="co">#&gt; AIC: 1739.18</span></a>
<a class="sourceLine" id="cb1-17" data-line-number="17"><span class="kw"><a href="https://rdrr.io/r/base/summary.html">summary</a></span>(M.attendance)</a>
<a class="sourceLine" id="cb1-18" data-line-number="18"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb1-19" data-line-number="19"><span class="co">#&gt; Call: glm.cmp(formula = daysabs ~ gender + math + prog, data = attendance)</span></a>
<a class="sourceLine" id="cb1-20" data-line-number="20"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb1-21" data-line-number="21"><span class="co">#&gt; Deviance Residuals: </span></a>
<a class="sourceLine" id="cb1-22" data-line-number="22"><span class="co">#&gt;     Min       1Q   Median       3Q      Max  </span></a>
<a class="sourceLine" id="cb1-23" data-line-number="23"><span class="co">#&gt; -2.2160  -1.1432  -0.4102   0.3175   2.8865  </span></a>
<a class="sourceLine" id="cb1-24" data-line-number="24"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb1-25" data-line-number="25"><span class="co">#&gt; Linear Model Coefficients:</span></a>
<a class="sourceLine" id="cb1-26" data-line-number="26"><span class="co">#&gt;                Estimate Std.Err Z value Pr(&gt;|z|)    </span></a>
<a class="sourceLine" id="cb1-27" data-line-number="27"><span class="co">#&gt; (Intercept)      2.7488  0.1873   14.68  &lt; 2e-16 ***</span></a>
<a class="sourceLine" id="cb1-28" data-line-number="28"><span class="co">#&gt; gendermale      -0.2360  0.1160   -2.03   0.0419 *  </span></a>
<a class="sourceLine" id="cb1-29" data-line-number="29"><span class="co">#&gt; math            -0.0068  0.0024   -2.88   0.0039 ** </span></a>
<a class="sourceLine" id="cb1-30" data-line-number="30"><span class="co">#&gt; progAcademic    -0.4258  0.1669   -2.55   0.0107 *  </span></a>
<a class="sourceLine" id="cb1-31" data-line-number="31"><span class="co">#&gt; progVocational  -1.2661  0.1873   -6.76  1.4e-11 ***</span></a>
<a class="sourceLine" id="cb1-32" data-line-number="32"><span class="co">#&gt; ---</span></a>
<a class="sourceLine" id="cb1-33" data-line-number="33"><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></a>
<a class="sourceLine" id="cb1-34" data-line-number="34"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb1-35" data-line-number="35"><span class="co">#&gt; (Dispersion parameter for Mean-CMP estimated to be  0.02419 )</span></a>
<a class="sourceLine" id="cb1-36" data-line-number="36"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb1-37" data-line-number="37"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb1-38" data-line-number="38"><span class="co">#&gt;     Null deviance: 462.96  on 313 degrees of freedom</span></a>
<a class="sourceLine" id="cb1-39" data-line-number="39"><span class="co">#&gt; Residual deviance: 383.08  on 309 degrees of freedom</span></a>
<a class="sourceLine" id="cb1-40" data-line-number="40"><span class="co">#&gt; </span></a>
<a class="sourceLine" id="cb1-41" data-line-number="41"><span class="co">#&gt; AIC: 1739.18</span></a></code></pre></div>
</div>
<div id="underdispersed-takeover-bids-data" class="section level3">
<h3 class="hasAnchor">
<a href="#underdispersed-takeover-bids-data" class="anchor"></a>Underdispersed takeover bids data</h3>
</div>
<div id="underdispersed-cotton-bolls-data" class="section level3">
<h3 class="hasAnchor">
<a href="#underdispersed-cotton-bolls-data" class="anchor"></a>Underdispersed Cotton bolls data</h3>
</div>
</div>
<div id="other-packages-for-fitting-conway-maxwell-poisson-model" class="section level2">
<h2 class="hasAnchor">
<a href="#other-packages-for-fitting-conway-maxwell-poisson-model" class="anchor"></a>Other packages for fitting Conway-Maxwell Poisson Model</h2>
<p><code>CompGLM</code>, <code>COMPoissonReg</code>, <code>compoisson</code></p>
<p>Note the various macros within the <code>vignette</code> section of the metadata block above. These are required in order to instruct R how to build the vignette. Note that you should change the <code>title</code> field and the <code>\VignetteIndexEntry</code> to match the title of your vignette.</p>
</div>
<div id="styles" class="section level2">
<h2 class="hasAnchor">
<a href="#styles" class="anchor"></a>Styles</h2>
<p>The <code>html_vignette</code> template includes a basic CSS theme. To override this theme you can specify your own CSS in the document metadata as follows:</p>
<pre><code>output: 
  rmarkdown::html_vignette:
    css: mystyles.css</code></pre>
</div>
<div id="figures" class="section level2">
<h2 class="hasAnchor">
<a href="#figures" class="anchor"></a>Figures</h2>
<p>The figure sizes have been customised so that you can easily put two images side-by-side.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="kw"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>)</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="kw"><a href="https://rdrr.io/r/graphics/plot.html">plot</a></span>(<span class="dv">10</span><span class="op">:</span><span class="dv">1</span>)</a></code></pre></div>
<div class="figure">
<img src="mpcmp_files/figure-html/unnamed-chunk-2-1.png" alt="test" width="700"><img src="mpcmp_files/figure-html/unnamed-chunk-2-2.png" alt="test" width="700"><p class="caption">
test
</p>
</div>
<p>You can enable figure captions by <code>fig_caption: yes</code> in YAML:</p>
<pre><code>output:
  rmarkdown::html_vignette:
    fig_caption: yes</code></pre>
<p>Then you can use the chunk option <code>fig.cap = "Your figure caption."</code> in <strong>knitr</strong>.</p>
</div>
<div id="more-examples" class="section level2">
<h2 class="hasAnchor">
<a href="#more-examples" class="anchor"></a>More Examples</h2>
<p>You can write math expressions, e.g. <span class="math display">\[Y = X\beta + \epsilon\]</span>, footnotes<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>, and tables, e.g. using <code><a href="https://rdrr.io/pkg/knitr/man/kable.html">knitr::kable()</a></code>.</p>
<table class="table">
<thead><tr class="header">
<th></th>
<th align="right">mpg</th>
<th align="right">cyl</th>
<th align="right">disp</th>
<th align="right">hp</th>
<th align="right">drat</th>
<th align="right">wt</th>
<th align="right">qsec</th>
<th align="right">vs</th>
<th align="right">am</th>
<th align="right">gear</th>
<th align="right">carb</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Mazda RX4</td>
<td align="right">21.0</td>
<td align="right">6</td>
<td align="right">160.0</td>
<td align="right">110</td>
<td align="right">3.90</td>
<td align="right">2.620</td>
<td align="right">16.46</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td>Mazda RX4 Wag</td>
<td align="right">21.0</td>
<td align="right">6</td>
<td align="right">160.0</td>
<td align="right">110</td>
<td align="right">3.90</td>
<td align="right">2.875</td>
<td align="right">17.02</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td>Datsun 710</td>
<td align="right">22.8</td>
<td align="right">4</td>
<td align="right">108.0</td>
<td align="right">93</td>
<td align="right">3.85</td>
<td align="right">2.320</td>
<td align="right">18.61</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">4</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td>Hornet 4 Drive</td>
<td align="right">21.4</td>
<td align="right">6</td>
<td align="right">258.0</td>
<td align="right">110</td>
<td align="right">3.08</td>
<td align="right">3.215</td>
<td align="right">19.44</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td>Hornet Sportabout</td>
<td align="right">18.7</td>
<td align="right">8</td>
<td align="right">360.0</td>
<td align="right">175</td>
<td align="right">3.15</td>
<td align="right">3.440</td>
<td align="right">17.02</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td>Valiant</td>
<td align="right">18.1</td>
<td align="right">6</td>
<td align="right">225.0</td>
<td align="right">105</td>
<td align="right">2.76</td>
<td align="right">3.460</td>
<td align="right">20.22</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td>Duster 360</td>
<td align="right">14.3</td>
<td align="right">8</td>
<td align="right">360.0</td>
<td align="right">245</td>
<td align="right">3.21</td>
<td align="right">3.570</td>
<td align="right">15.84</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td>Merc 240D</td>
<td align="right">24.4</td>
<td align="right">4</td>
<td align="right">146.7</td>
<td align="right">62</td>
<td align="right">3.69</td>
<td align="right">3.190</td>
<td align="right">20.00</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">4</td>
<td align="right">2</td>
</tr>
<tr class="odd">
<td>Merc 230</td>
<td align="right">22.8</td>
<td align="right">4</td>
<td align="right">140.8</td>
<td align="right">95</td>
<td align="right">3.92</td>
<td align="right">3.150</td>
<td align="right">22.90</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">4</td>
<td align="right">2</td>
</tr>
<tr class="even">
<td>Merc 280</td>
<td align="right">19.2</td>
<td align="right">6</td>
<td align="right">167.6</td>
<td align="right">123</td>
<td align="right">3.92</td>
<td align="right">3.440</td>
<td align="right">18.30</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">4</td>
<td align="right">4</td>
</tr>
</tbody>
</table>
<p>Also a quote using <code><a href="https://rdrr.io/r/base/Comparison.html">&gt;</a></code>:</p>
<p>The dispersion <span class="math inline">\(\nu\)</span> can in turn be modelled via its own regression model using a set of covariates <span class="math inline">\(\tilte{X}\)</span>, with the natural link being <span class="math inline">\(\nu = exp(\tilde{X}^{\top}\gamma))\)</span> to ensure non-negativity. The set of covariates <span class="math inline">\(\tilde{X}\)</span> can coincide with <span class="math inline">\(X\)</span>, share common components with <span class="math inline">\(X\)</span>, or be distinct altogether.</p>
<p>There are other <code>R</code> packages to deal with CMP models and they all help the writing and contruction of this package..</p>
<ul>
<li>
<code>compoisson</code>: Routines for density and moments of the COM-Poisson distribution under original parametrization by <span class="citation">(<span class="citeproc-not-found" data-reference-id="R-compoisson"><strong>???</strong></span>)</span>
</li>
<li>
<code>CompGLM</code>: Fit COM-Poisson models under original parametrization (includes dispersion modeling) by <span class="citation">(<span class="citeproc-not-found" data-reference-id="R-CompGLM"><strong>???</strong></span>)</span>.</li>
<li>
<code>COMPoissonReg</code>: Fit COM-Poisson models under original parametrization (includes zero-inflation and dispersion modeling) by <span class="citation">(<span class="citeproc-not-found" data-reference-id="R-COMPoissonReg"><strong>???</strong></span>)</span>.</li>
<li>
<code>glmmTMB</code>: Fit (among other) COM-Poisson models under a different mean-parametrization (includes zero-inflation, dispersion modeling and random effects) by <span class="citation">(<span class="citeproc-not-found" data-reference-id="R-glmmTMB"><strong>???</strong></span>)</span>.</li>
</ul>
</div>
<div id="references" class="section level2 unnumbered">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<div id="refs" class="references">
<div id="ref-Huang2017b">
<p>Huang, Alan. 2017. “Mean-parametrized Conway–Maxwell–Poisson regression models for dispersed counts.” <em>Statistical Modelling</em> 17 (6): 359–80. <a href="https://doi.org/10.1177/1471082X17697749">https://doi.org/10.1177/1471082X17697749</a>.</p>
</div>
<div id="ref-Marschner2011">
<p>Marschner, Ian C. 2011. “glm2: Fitting Generalized Linear Models with Convergence Problems.” <em>R Journal</em> 3 (2): 12.</p>
</div>
<div id="ref-Sellers2010">
<p>Sellers, Kimberly F., and Galit Shmueli. 2010. “A flexible regression model for count data.” <em>Annals of Applied Statistics</em> 4 (2): 943–61. <a href="https://doi.org/10.1214/09-AOAS306">https://doi.org/10.1214/09-AOAS306</a>.</p>
</div>
<div id="ref-Shmueli2005">
<p>Shmueli, G., T.P Minka, J.B Kadane, S. Borle, and P. Boatwright. 2005. “A useful distribution for fitting discrete data:revival of the conway-Maxwell_Poisson distribution.” <em>Applied Statistics</em> 54 (1): 127–42. <a href="https://doi.org/10.1111/j.1467-9876.2005.00474.x">https://doi.org/10.1111/j.1467-9876.2005.00474.x</a>.</p>
</div>
</div>
</div>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>A footnote here.<a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">

        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#intro">Introduction</a></li>
      <li><a href="#cmpintro">Conway-Maxwell-Poisson Distributions</a></li>
      <li><a href="#mpcmpintro">Mean-Parametrized Conway-Maxwell-Poisson Regression</a></li>
      <li><a href="#model-fitting">Model fitting</a></li>
      <li><a href="#dist_theory">Distribution theory for likelihood estimation</a></li>
      <li><a href="#modelling-function-in-mpcmp">Modelling function in mpcmp</a></li>
      <li><a href="#diagnostics">Diagnostics</a></li>
      <li><a href="#examples">Examples</a></li>
      <li><a href="#other-packages-for-fitting-conway-maxwell-poisson-model">Other packages for fitting Conway-Maxwell Poisson Model</a></li>
      <li><a href="#styles">Styles</a></li>
      <li><a href="#figures">Figures</a></li>
      <li><a href="#more-examples">More Examples</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</div>
      </div>

</div>



      <footer><div class="copyright">
  <p>Developed by Thomas Fung, Aya Alwan, Justin Wishart, Alan Huang.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
